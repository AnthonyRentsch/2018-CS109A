{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS-109A Introduction to Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Lab 9: Regression Trees, Bagged Trees, Random Forests and Boosting\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2018**<br/>\n",
    "**Instructors:** Pavlos Protopapas and Kevin Rader<br/>\n",
    "**Lab Instructor:** Kevin Rader (today at least)<br/>\n",
    "**Authors:** Kevin Rader, Rahul Dave\n",
    "\n",
    "---\n",
    "We will look here into the practicalities of fitting regression trees, random forests, and boosted trees. These involve out-of-bound estmates and cross-validation, and how you might want to deal with hyperparameters in these models. Along the way we will play a little bit with different loss functions, so that you start thinking about what goes in general into cooking up a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn.apionly as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "First, the data. We will be attempting to predict the presidential election results (at the county level) from 2016, measured as 'votergap' = (trump - clinton) in percentage points, based mostly on demographic features of those counties.  Let's quick take a peak at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elect_df = pd.read_csv(\"data/county_level_election.csv\")\n",
    "elect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split 80/20 train-test\n",
    "X = elect_df[['population','hispanic','minority','female','unemployed','income','nodegree','bachelor','inactivity','obesity','density','cancer']]\n",
    "response = elect_df['votergap']\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,response,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ytrain)\n",
    "Xtrain.hist(column=['minority', 'population','hispanic','female']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you describe these variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(elect_df.shape)\n",
    "print(Xtrain.shape)\n",
    "print(Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Trees\n",
    "\n",
    "We will start by using a simple Decision Tree Regressor to predict votergap. Thats not the aim of this lab, so we'll run a few of these models without any cross-validation or 'regularization' just to illustrate what is going on.\n",
    "\n",
    "This is what you ought to keep in mind about decision trees.\n",
    "\n",
    "from the docs:\n",
    "```\n",
    "max_depth : int or None, optional (default=None)\n",
    "The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "min_samples_split : int, float, optional (default=2)\n",
    "```\n",
    "\n",
    "- The deeper the tree, the more prone you are to overfitting.\n",
    "- The smaller `min_samples_split`, the more the overfitting. One may use `min_samples_leaf` instead. More samples per leaf, the higher the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "#x = np.arange(0, 2*np.pi, 0.1)\n",
    "#y = np.sin(x) + 0.1*np.random.normal(size=x.shape[0])\n",
    "x = Xtrain['minority'].values\n",
    "o = np.argsort(x)\n",
    "x = x[o]\n",
    "y = ytrain.values\n",
    "y = y[o]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y, '.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log(x),y, '.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\">**Exercise 0**</div>\n",
    "Which of the two versions of 'minority' would be a better choice to use as a predictor for inference?  For prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:2px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log(x),y,'.')\n",
    "xx = np.log(x).reshape(-1,1)\n",
    "for i in [1,2]:\n",
    "    dtree = DecisionTreeRegressor(max_depth=i)\n",
    "    dtree.fit(xx, y)\n",
    "    plt.plot(np.log(x), dtree.predict(xx), label=str(i), alpha=1-i/10, lw=4)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log(x),y,'.')\n",
    "xx = np.log(x).reshape(-1,1)\n",
    "for i in [500,200,100,20]:\n",
    "    dtree = DecisionTreeRegressor(min_samples_split=i)\n",
    "    dtree.fit(xx, y)\n",
    "    plt.plot(np.log(x), dtree.predict(xx), label=str(i), alpha=0.8, lw=4)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log(x),y,'.')\n",
    "xx = np.log(x).reshape(-1,1)\n",
    "for i in [500,200,100,20]:\n",
    "    dtree = DecisionTreeRegressor(max_depth=6, min_samples_split=i)\n",
    "    dtree.fit(xx, y)\n",
    "    plt.plot(np.log(x), dtree.predict(xx), label=str(i), alpha=0.8, lw=4)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's also include logminority as a predictor going forward\n",
    "xtemp = np.log(Xtrain['minority'].values)\n",
    "Xtrain = Xtrain.assign(logminority = xtemp)\n",
    "Xtest = Xtest.assign(logminority = np.log(Xtest['minority'].values))\n",
    "Xtrain.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\">**Exercise 1**</div>\n",
    "1. Perform 5-fold cross-validation to determine what the best `max_depth` would be for a single regression tree using the entire 'Xtrain' feature set.\n",
    "2. Visualize the results with mean +/- 2 sd's across the validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# your code here\n",
    "depths = list(range(1, 21))\n",
    "train_scores = []\n",
    "cvmeans = []\n",
    "cvstds = []\n",
    "cv_scores = []\n",
    "for depth in depths:\n",
    "    dtree = DecisionTreeRegressor(max_depth=depth)\n",
    "    # Perform 5-fold cross validation and store results\n",
    "\n",
    "cvmeans = np.array(cvmeans)\n",
    "cvstds = np.array(cvstds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# plot means and shade the 2 SD interval\n",
    "\n",
    "#plt.fill_between(depths, cvmeans - 2*cvstds, cvmeans + 2*cvstds, alpha=0.3);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:2px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok with this discussion in mind, lets improve this model by Bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap-Aggregating (called Bagging)\n",
    "\n",
    "Whats the basic idea?\n",
    "\n",
    "- A Single Decision tree is likely to overfit.\n",
    "- So lets introduce replication through Bootstrap sampling.\n",
    "- **Bagging** uses bootstrap resampling to create different training datasets. This way each training will give us a different tree.\n",
    "- Added bonus: the left off points can be used to as a natural \"validation\" set, so no need to \n",
    "- Since we have many trees that we will **average over for prediction**, we can choose a large `max_depth` and we are ok as we will rely on the law of large numbers to shrink this large variance, low bias approach for each individual tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "ntrees = 500\n",
    "estimators = []\n",
    "R2s = []\n",
    "yhats_test = np.zeros((Xtest.shape[0], ntrees))\n",
    "\n",
    "plt.plot(np.log(x),y,'.')\n",
    "for i in range(ntrees):\n",
    "    simpletree = DecisionTreeRegressor(max_depth=3)\n",
    "    boot_xx, boot_y = resample(Xtrain[['logminority']], ytrain)\n",
    "    estimators = np.append(estimators,simpletree.fit(boot_xx, boot_y))\n",
    "    R2s = np.append(R2s,simpletree.score(Xtest[['logminority']], ytest))\n",
    "    yhats_test[:,i] = simpletree.predict(Xtest[['logminority']])\n",
    "    plt.plot(np.log(x), simpletree.predict(np.log(x).reshape(-1,1)), 'red', alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhats_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\">**Exercise 2**</div>\n",
    "1. Edit the code below (which is just copied from above) to refit many bagged trees on the entire xtrain feature set (without the plot...lots of predictors now so difficult to plot). \n",
    "2. Summarize how each of the separate trees performed (both numerically and visually) using $R^2$ as the metric.  How do they perform on average?\n",
    "3. Combine the trees into one prediction and evaluate it using $R^2$.\n",
    "4. Briefly discuss the results.  How will the results above change if 'max_depth=4' is increased?  What if it is decreased?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "ntrees = 500\n",
    "estimators = []\n",
    "R2s = []\n",
    "yhats_test = np.zeros((Xtest.shape[0], ntrees))\n",
    "\n",
    "for i in range(ntrees):\n",
    "    dtree = DecisionTreeRegressor(max_depth=3)\n",
    "    boot_xx, boot_y = resample(Xtrain[['logminority']], ytrain)\n",
    "    estimators = np.append(estimators,dtree.fit(boot_xx, boot_y))\n",
    "    R2s = np.append(R2s,dtree.score(Xtest[['logminority']], ytest))\n",
    "    yhats_test[:,i] = dtree.predict(Xtest[['logminority']])\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:2px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n",
    "What's the basic idea?\n",
    "\n",
    "Bagging alone is not enough randomization, because even after bootstrapping, we are mainly training on the same data points using the same variablesn, and will retain much of the overfitting.\n",
    "\n",
    "So we will build each tree by splitting on \"random\" subset of predictors at each split (hence, each is a 'random tree').  This can't be done in with just one predcitor, but with more predictors we can choose what predictors to split on randomly and how many to do this on.  Then we combine many 'random trees' together by averaging their predictions, and this gets us a forest of random trees: a **random forest**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create a hyper-param Grid. We are preparing to use the bootstrap points not used in training for validation.\n",
    "\n",
    "```\n",
    "max_features : int, float, string or None, optional (default=”auto”)\n",
    "- The number of features to consider when looking for the best split.\n",
    "```\n",
    "\n",
    "- `max_features`: Default splits on all the features and is probably prone to overfitting. You'll want to validate on this. \n",
    "- You can \"validate\" on the trees `n_estimators` as well but many a times you will just look for the plateau in the trees as seen below.\n",
    "- From decision trees you get the `max_depth`, `min_samples_split`, and `min_samples_leaf` as well but you might as well leave those at defaults to get a maximally expanded tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from \n",
    "# Adventures in scikit-learn's Random Forest by Gregory Saunders\n",
    "from itertools import product\n",
    "from collections import OrderedDict\n",
    "param_dict = OrderedDict(\n",
    "    n_estimators = [400, 600, 800],\n",
    "    max_features = [0.2, 0.4, 0.6, 0.8]\n",
    ")\n",
    "\n",
    "param_dict.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the OOB score.\n",
    "\n",
    "We have been putting \"validate\" in quotes. This is because the bootstrap gives us left-over points! So we'll now engage in our very own version of a grid-search, done over the out-of-bag scores that `sklearn` gives us for free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure ytrain is the correct data type...in case you have warnings\n",
    "#print(yytrain.shape,ytrain.shape,Xtrain.shape)\n",
    "#ytrain = np.ravel(ytrain)\n",
    "\n",
    "#Let's Cross-val. on the two 'hyperparameters' we based our grid on earlier\n",
    "results = {}\n",
    "estimators= {}\n",
    "for ntrees, maxf in product(*param_dict.values()):\n",
    "    params = (ntrees, maxf)\n",
    "    est = RandomForestRegressor(oob_score=True, \n",
    "                                n_estimators=ntrees, max_features=maxf, max_depth=50, n_jobs=-1)\n",
    "    est.fit(Xtrain, ytrain)\n",
    "    results[params] = est.oob_score_\n",
    "    estimators[params] = est\n",
    "outparams = max(results, key = results.get)\n",
    "outparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf1 = estimators[outparams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally you can find the **feature importance** of each predictor in this random forest model. Whenever a feature is used in a tree in the forest, the algorithm will log the decrease in the splitting criterion (such as gini). This is accumulated over all trees and reported in `est.feature_importances_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(rf1.feature_importances_,index=list(Xtrain)).sort_values().plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our response isn't very symmetric, we may want to suppress outliers by using the `mean_absolute_error` instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(ytest, rf1.predict(Xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\">**Bonus Exercise (we will likely skip this)**</div>\n",
    "1. Tune the 'RandomForestRegressor' above to minimize 'mean_absolute_error' instead of the default ____________\n",
    "\n",
    "*Note: `sklearn` supports this (`criterion='mae'`) since v0.18, but does not have completely arbitrary loss functions for Random Forests.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:2px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: instead of using oob scoring, we could do cross-validation, and a cv of 3 will roughly be comparable (same approximate train-vs.-validation set sizes). But this will take much more time as you are doing the fit 3 times plus the bootstraps. So at least three times as long!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_dict2 = OrderedDict(\n",
    "    n_estimators = [600],\n",
    "    max_features = [0.2, 0.4, 0.6, 0.8]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "est2 = RandomForestRegressor(oob_score=False)\n",
    "gs = GridSearchCV(est2, param_grid = param_dict2, cv=3, n_jobs=-1)\n",
    "gs.fit(Xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = gs.best_estimator_\n",
    "rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\">**Exercise 3: thinking questions**</div>\n",
    "1. What are the 3 *hyperparameters* for a random forest (one of the hyperparameters come in many *flavors*)?\n",
    "2. Which hyperparameters need to be tuned?\n",
    "3. How would you go about tuning these hyperparemeters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:2px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing error as a function of the proportion of predictors at each split\n",
    "\n",
    "Let's look to see how `max_features` affects performance on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from http://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html\n",
    "\n",
    "feats = param_dict['max_features']\n",
    "# \n",
    "error_rate = OrderedDict((label, []) for label in feats)\n",
    "\n",
    "# Range of `n_estimators` values to explore.\n",
    "min_estimators = 200\n",
    "step_estimators = 100\n",
    "num_steps = 3\n",
    "max_estimators = min_estimators + step_estimators*num_steps\n",
    "for label in feats:\n",
    "    for i in range(min_estimators, max_estimators+1, step_estimators):\n",
    "        clf = RandomForestRegressor(oob_score=True, max_features=label)\n",
    "        clf.set_params(n_estimators=i)\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "\n",
    "        # Record the OOB error for each `n_estimators=i` setting.\n",
    "        oob_error = 1 - clf.oob_score_\n",
    "        error_rate[label].append((i, oob_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the \"OOB error rate\" vs. \"n_estimators\" plot.\n",
    "for label, clf_err in error_rate.items():\n",
    "    xs, ys = zip(*clf_err)\n",
    "    plt.plot(xs, ys, label=label)\n",
    "\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"OOB error rate\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting Regression Trees\n",
    "\n",
    "Adaboost Classification, which you will be doing in your homework, is a special case of a gradient-boosted algorithm. Gradient Bossting is very state of the art, and has major connections to logistic regression, gradient descent in a functional space, and search in information space. See Schapire and Freund's MIT Press book for details (Google is a wonderful thing).\n",
    "\n",
    "But briefly, let us cover the idea here. The idea is that we will use a bunch of weak 'learners' (aka, models) which are fit sequentially. The first one fits the signal, the second one the first model's residual, the third the second model's residual, and so on. At each stage we upweight the places that our previous model did badly on. First let us illustrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "estab = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=1), n_estimators=200, learning_rate=1.0)\n",
    "estab.fit(xx, y)\n",
    "staged_predict_generator = estab.staged_predict(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from http://nbviewer.jupyter.org/github/pprett/pydata-gbrt-tutorial/blob/master/gbrt-tutorial.ipynb\n",
    "import time\n",
    "from IPython import display\n",
    "plt.plot(xx, y, '.');\n",
    "counter = 0\n",
    "for stagepred in staged_predict_generator:\n",
    "    counter = counter + 1\n",
    "    if counter in [1, 2, 4, 8, 10, 50, 100, 200]:\n",
    "        plt.plot(xx, stagepred, alpha=0.7, label=str(counter), lw=4)\n",
    "        plt.legend();\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(counter, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so this demonstration helps us understand some things about boosting.\n",
    "\n",
    "- `n_estimators` is the number of trees, and thus the stage in the fitting. It also controls the complexity for us. The more trees we have the more we fit to the tiny details.\n",
    "- `staged_predict` gives us the prediction at each step\n",
    "- once again `max_depth` from the underlying decision tree tells us the depth of the tree. But here it tells us the amount of features interactions we have, not just the scale of our fit. But clearly it increases the variance again.\n",
    "\n",
    "Ideas from decision trees remain. For example, increase `min_samples_leaf` or decrease `max_depth` to reduce variance and increase the bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\">**Exercise 4**</div>\n",
    "1. What do you expect to happen if you increase `max_depth` to 5?  Edit the code above to explore the result.\n",
    "2. What do you expect to happen if you put `max_depth` back to 1 and decrease the `learning_rate` to 0.1?  Edit the code above to explore the result.\n",
    "3. Do a little work to find some sort of 'best' values of `max_depth` and `learning_rate`.  Does this result make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:2px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: what's the relationship between residuals and the gradient?\n",
    "\n",
    "Pavlos showed in class that for the squared loss, taking the gradient in the \"data point functional space\", ie a N-d space for N data points with each variable being $f(x_i)$ just gives us the residuals. It turns out that the gradient descent is a more general idea, and one can use this for different losses. And the upweighting of poorly fit points in AdaBoost is simply a weighing by gradient. If the gradient (or residual) is high it means you are far away from optimum in this functional space, and if you are at 0, you have a flat gradient!\n",
    "\n",
    "The ideas from the general theory of gradient descent tell us this: we can slow the learning by shrinking the predictions of each tree by some small number, which is called the learning_rate (learning_rate). This \"shrinkage\" helps us not overshoot, but for a finite number of iterations also simultaneously ensures we dont overfit by being in the neighboorhood of the minimum rather than just at it! But we might need to increase the iterations some to get into the minimum area."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
